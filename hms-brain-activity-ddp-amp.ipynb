{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8112003,"sourceType":"datasetVersion","datasetId":4792056}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install dask-image","metadata":{"execution":{"iopub.status.busy":"2024-04-14T02:28:59.354266Z","iopub.execute_input":"2024-04-14T02:28:59.354660Z","iopub.status.idle":"2024-04-14T02:29:15.402683Z","shell.execute_reply.started":"2024-04-14T02:28:59.354631Z","shell.execute_reply":"2024-04-14T02:29:15.401495Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting dask-image\n  Downloading dask_image-2023.8.1-py2.py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: dask>=2023.2.0 in /opt/conda/lib/python3.10/site-packages (from dask[array]>=2023.2.0->dask-image) (2024.4.0)\nRequirement already satisfied: numpy>=1.18 in /opt/conda/lib/python3.10/site-packages (from dask-image) (1.26.4)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from dask-image) (1.11.4)\nCollecting pims>=0.4.1 (from dask-image)\n  Downloading PIMS-0.6.1.tar.gz (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tifffile>=2018.10.18 in /opt/conda/lib/python3.10/site-packages (from dask-image) (2023.12.9)\nRequirement already satisfied: pandas>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from dask-image) (2.1.4)\nRequirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (8.1.7)\nRequirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (2.2.1)\nRequirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (2024.2.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (21.3)\nRequirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (1.4.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (6.0.1)\nRequirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (0.12.1)\nRequirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (6.11.0)\nRequirement already satisfied: dask-expr<1.1,>=1.0 in /opt/conda/lib/python3.10/site-packages (from dask[dataframe]>=2023.2.0->dask-image) (1.0.9)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->dask-image) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->dask-image) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->dask-image) (2023.4)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from pims>=0.4.1->dask-image) (2.33.1)\nCollecting slicerator>=0.9.8 (from pims>=0.4.1->dask-image)\n  Downloading slicerator-1.1.0-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pyarrow>=7.0.0 in /opt/conda/lib/python3.10/site-packages (from dask-expr<1.1,>=1.0->dask[dataframe]>=2023.2.0->dask-image) (15.0.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (3.17.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (3.1.1)\nRequirement already satisfied: locket in /opt/conda/lib/python3.10/site-packages (from partd>=1.2.0->dask>=2023.2.0->dask[array]>=2023.2.0->dask-image) (1.0.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->dask-image) (1.16.0)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio->pims>=0.4.1->dask-image) (9.5.0)\nDownloading dask_image-2023.8.1-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading slicerator-1.1.0-py3-none-any.whl (10 kB)\nBuilding wheels for collected packages: pims\n  Building wheel for pims (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pims: filename=PIMS-0.6.1-py3-none-any.whl size=82615 sha256=6908fbe00d8039e0a458eb35173b60fe914a6705042cac222172967d733fe38b\n  Stored in directory: /root/.cache/pip/wheels/cc/bf/3e/bfa77232d942f8244145f9c713b6b38f6ef04b6fb5c021c114\nSuccessfully built pims\nInstalling collected packages: slicerator, pims, dask-image\nSuccessfully installed dask-image-2023.8.1 pims-0.6.1 slicerator-1.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torchvision.models import resnet50\nimport torch.multiprocessing as mp\nimport torch.distributed as dist\nimport dask.array as da\nimport dask.dataframe as dd\nfrom dask_image.imread import imread\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-04-14T02:33:03.018881Z","iopub.execute_input":"2024-04-14T02:33:03.019857Z","iopub.status.idle":"2024-04-14T02:33:03.451340Z","shell.execute_reply.started":"2024-04-14T02:33:03.019819Z","shell.execute_reply":"2024-04-14T02:33:03.450519Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"os.listdir(\"/kaggle/input/\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T00:21:02.682628Z","iopub.execute_input":"2024-04-14T00:21:02.684002Z","iopub.status.idle":"2024-04-14T00:21:02.694330Z","shell.execute_reply.started":"2024-04-14T00:21:02.683930Z","shell.execute_reply":"2024-04-14T00:21:02.693055Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['hms-brain-activity']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"def create_splits(data_dir, output_dir, train_size=0.7, val_size=0.15, test_size=0.15):\n    classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n    splits = {'train': train_size, 'val': val_size, 'test': test_size}\n\n    # Ensure the split sizes sum to 1\n    assert sum(splits.values()) == 1, \"Sum of split sizes should be 1.\"\n\n    # Create output directories for the splits\n    for split in splits.keys():\n        for cls in classes:\n            os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)\n\n    # Process each class directory\n    for cls in classes:\n        class_dir = os.path.join(data_dir, cls)\n        images = [img for img in os.listdir(class_dir) if img.lower().endswith(('png', 'jpg', 'jpeg'))]\n        # Create stratified splits\n        train_val, test = train_test_split(images, test_size=splits['test'], random_state=42, stratify=None)\n        train, val = train_test_split(train_val, test_size=splits['val'] / (splits['train'] + splits['val']), random_state=42, stratify=None)\n\n        # Function to copy files to their respective directories\n        def copy_files(files, split):\n            for f in files:\n                src = os.path.join(class_dir, f)\n                dst = os.path.join(output_dir, split, cls, f)\n                shutil.copy(src, dst)\n\n        # Copy files to respective split directories\n        copy_files(train, 'train')\n        copy_files(val, 'val')\n        copy_files(test, 'test')\n\nif __name__ == \"__main__\":\n    data_dir = '/kaggle/input/hms-brain-activity/dataset/'\n    output_dir = '/kaggle/working/dataset_splits/'\n    create_splits(data_dir, output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T01:39:53.995334Z","iopub.execute_input":"2024-04-14T01:39:53.995875Z","iopub.status.idle":"2024-04-14T01:42:14.290444Z","shell.execute_reply.started":"2024-04-14T01:39:53.995850Z","shell.execute_reply":"2024-04-14T01:42:14.289614Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Resnet 50 - Fine-Tuning / Transfer Learning on Spectrogram Dataset\n\n# Set device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Data directories\ndata_dir = '/kaggle/working/dataset_splits/'\ntrain_dir = f'{data_dir}/train'\nval_dir = f'{data_dir}/val'\ntest_dir = f'{data_dir}/test'\n\n# Transformations\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Data Loaders\ntrain_dataset = datasets.ImageFolder(train_dir, transform=transform)\nval_dataset = datasets.ImageFolder(val_dir, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Model setup\nmodel = models.resnet50(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, len(train_dataset.classes))  # Adjusting the last layer\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n\n# Training Function\ndef train_model(num_epochs):\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * images.size(0)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n\n        validate_model()\n\n# Validation Function\ndef validate_model():\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n\n# Main\nif __name__ == \"__main__\":\n    train_model(num_epochs=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T04:26:53.982039Z","iopub.execute_input":"2024-04-14T04:26:53.982409Z","iopub.status.idle":"2024-04-14T05:26:16.579486Z","shell.execute_reply.started":"2024-04-14T04:26:53.982375Z","shell.execute_reply":"2024-04-14T05:26:16.578338Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:04<00:00, 25.0MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 1.8131\nValidation Accuracy: 25.51%\nEpoch 2/10, Loss: 1.7796\nValidation Accuracy: 26.73%\nEpoch 3/10, Loss: 1.7760\nValidation Accuracy: 28.41%\nEpoch 4/10, Loss: 1.7589\nValidation Accuracy: 28.22%\nEpoch 5/10, Loss: 1.7668\nValidation Accuracy: 26.24%\nEpoch 6/10, Loss: 1.7683\nValidation Accuracy: 28.10%\nEpoch 7/10, Loss: 1.7627\nValidation Accuracy: 25.67%\nEpoch 8/10, Loss: 1.7572\nValidation Accuracy: 25.29%\nEpoch 9/10, Loss: 1.7509\nValidation Accuracy: 29.59%\nEpoch 10/10, Loss: 1.7508\nValidation Accuracy: 25.89%\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T01:46:54.689066Z","iopub.execute_input":"2024-04-14T01:46:54.689946Z","iopub.status.idle":"2024-04-14T01:46:54.731958Z","shell.execute_reply.started":"2024-04-14T01:46:54.689913Z","shell.execute_reply":"2024-04-14T01:46:54.731151Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"# Distributed Data Parallelizm\n\n# Data directories\ndata_dir = '/kaggle/working/dataset_splits/'\ntrain_dir = f'{data_dir}/train'\nval_dir = f'{data_dir}/val'\ntest_dir = f'{data_dir}/test'\n\n# def get_data_loader(batch_size, data_path):\n#     transform = transforms.Compose([\n#         transforms.Resize(256),\n#         transforms.CenterCrop(224),\n#         transforms.ToTensor(),\n#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#     ])\n# #     train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n#     _dataset = datasets.ImageFolder(data_path, transform=transform)\n#     data_loader = DataLoader(_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n#     return data_loader\n\n# With augmentation using dask\ndef get_data_loader(batch_size, data_path, train=True):\n    if train:\n        transform = transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.RandomRotation(10),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n    else:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n    _dataset = datasets.ImageFolder(data_path, transform=transform)\n    data_loader = DataLoader(_dataset, batch_size=batch_size, shuffle=train, num_workers=4, pin_memory=True)\n    return data_loader\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n    torch.cuda.set_device(rank)\n\ndef save_checkpoint(model, optimizer, epoch, filename=\"checkpoint.pth\"):\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.module.state_dict(),  # Note: unwrap the model from DDP\n        'optimizer_state_dict': optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)\n\ndef train(model, loader, optimizer, criterion, scaler, rank, epoch, save_interval):\n    model.train()\n    total_loss = 0.0\n    for batch_idx, (data, target) in enumerate(loader):\n        data, target = data.to(rank), target.to(rank)\n        optimizer.zero_grad()\n        with autocast():  # Using automatic mixed precision\n            output = model(data)\n            loss = criterion(output, target)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        total_loss += loss.item()\n\n        if rank == 0 and batch_idx % save_interval == 0:\n            save_checkpoint(model, optimizer, epoch, filename=f\"checkpoint_epoch_{epoch}_batch_{batch_idx}.pth\")\n    \n    return total_loss / len(loader)\n\n# Validation Function\ndef validate_model(model, val_loader, rank):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(rank), labels.to(rank)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n\n\ndef ddp_train(rank, world_size, epochs):\n    global train_dir, val_dir\n    setup(rank, world_size)\n    model = resnet50().to(rank)\n    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n    batch_size = 256\n    train_loader = get_data_loader(batch_size // world_size, train_dir, train=True)\n    val_loader = get_data_loader(batch_size // world_size, val_dir, train=False)\n    criterion = nn.CrossEntropyLoss().to(rank)\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n    scaler = GradScaler()  # Initialize the gradient scaler for AMP\n    save_interval = 100  # Define your interval for saving checkpoints\n\n    for epoch in range(epochs):\n        loss = train(model, train_loader, optimizer, criterion, scaler, rank, epoch, save_interval)\n        if rank == 0:\n            print(f\"Epoch {epoch+1}, Loss: {loss}\")\n            save_checkpoint(model, optimizer, epoch, filename=f\"checkpoint_epoch_{epoch}.pth\")\n            \n            validate_model(model, val_loader, rank)\n\n    if rank == 0:\n        save_checkpoint(model, optimizer, epochs, filename=\"final_checkpoint.pth\")\n    dist.destroy_process_group()\n\nif __name__ == \"__main__\":\n    world_size = 2 \n    epochs = 20\n#     mp.spawn(ddp_train, args=(world_size, epochs), nprocs=world_size, join=True)\n    processes = []\n    #mp.set_start_method(\"spawn\")\n    for rank in range(world_size):\n        p = mp.Process(target=ddp_train, args=(rank, world_size, epochs))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T03:19:43.457051Z","iopub.execute_input":"2024-04-14T03:19:43.457452Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 3.557675179094076\nValidation Accuracy: 19.19%\nEpoch 2, Loss: 1.8107595816254616\nValidation Accuracy: 19.19%\nEpoch 3, Loss: 1.8026292957365513\nValidation Accuracy: 18.24%\nEpoch 4, Loss: 1.796021254112323\nValidation Accuracy: 18.16%\nEpoch 5, Loss: 1.7934595321615536\nValidation Accuracy: 22.05%\nEpoch 6, Loss: 1.7822927708427112\nValidation Accuracy: 22.05%\nEpoch 7, Loss: 1.7736726043124993\nValidation Accuracy: 23.80%\nEpoch 8, Loss: 1.7747712917625904\nValidation Accuracy: 24.18%\nEpoch 9, Loss: 1.7644984213014443\nValidation Accuracy: 24.83%\nEpoch 10, Loss: 1.7621460258960724\nValidation Accuracy: 24.52%\nEpoch 11, Loss: 1.7574532441794872\nValidation Accuracy: 22.92%\nEpoch 12, Loss: 1.7439448311924934\nValidation Accuracy: 24.60%\nEpoch 13, Loss: 1.7423655614256859\nValidation Accuracy: 26.24%\nEpoch 14, Loss: 1.737213892241319\nValidation Accuracy: 26.12%\nEpoch 15, Loss: 1.7350679946442444\nValidation Accuracy: 28.03%\nEpoch 16, Loss: 1.7264911110202472\nValidation Accuracy: 26.92%\nEpoch 17, Loss: 1.7216266555090745\nValidation Accuracy: 28.52%\nEpoch 18, Loss: 1.7159402966499329\nValidation Accuracy: 27.76%\nEpoch 19, Loss: 1.7149387647708256\nValidation Accuracy: 28.90%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}